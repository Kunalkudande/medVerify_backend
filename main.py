from fastapi import FastAPI, File, UploadFile
import numpy as np
import tensorflow as tf
from tensorflow.keras.preprocessing import image
import cv2
import shutil
import uvicorn
from pathlib import Path
import requests  # âœ… Import requests (Fixes the error)

# âœ… Initialize FastAPI
app = FastAPI()

# âœ… Google Drive File ID
FILE_ID = "1S5rjYgyOANUt62DxFJVjeNNAG8g_F2Un"
MODEL_PATH = "medical_deepfake_cnn.keras"

# âœ… Function to download model from Google Drive
def download_model():
    if not Path(MODEL_PATH).exists() or os.path.getsize(MODEL_PATH) < 500000:  # Check if file exists and is at least 500KB
        print("ðŸ”„ Downloading model from Google Drive...")
        url = f"https://drive.google.com/uc?export=download&id={FILE_ID}"
        response = requests.get(url, stream=True)

        if response.status_code == 200:
            with open(MODEL_PATH, "wb") as f:
                for chunk in response.iter_content(1024):
                    f.write(chunk)
            print("âœ… Model downloaded successfully!")
        else:
            print("âŒ Failed to download model!")
            return False  # Prevents loading a broken model

    return True  # Download successful

# âœ… Lazy Loading: Load model only when needed
model = None

def get_model():
    global model
    if model is None:
        success = download_model()
        if success:  # Only load if the model is downloaded successfully
            try:
                model = tf.keras.models.load_model(MODEL_PATH)
                print("âœ… Model loaded successfully!")
            except Exception as e:
                print(f"âŒ Model loading failed: {e}")
                model = None  # Prevent crashing if model fails to load
    return model

# âœ… Class labels
class_labels = ["False-Benign (FB)", "False-Malicious (FM)", "True-Benign (TB)", "True-Malicious (TM)"]

# âœ… Function to preprocess and predict image
def predict_image(img_path):
    img = cv2.imread(img_path, cv2.IMREAD_COLOR)  # Ensure 3 channels
    img = cv2.resize(img, (224, 224))  # Resize
    img = img / 255.0  # Normalize
    img = np.expand_dims(img, axis=0)  # Add batch dimension

    model = get_model()  # Load model only when needed
    predictions = model.predict(img)
    predicted_class = np.argmax(predictions)
    confidence = np.max(predictions)

    return {"prediction": class_labels[predicted_class], "confidence": round(float(confidence), 2)}

# âœ… API endpoint to receive and predict image
@app.post("/predict/")
async def predict(file: UploadFile = File(...)):
    temp_file = Path(f"temp_{file.filename}")

    # Save uploaded file
    with temp_file.open("wb") as buffer:
        shutil.copyfileobj(file.file, buffer)

    # Predict the image
    result = predict_image(str(temp_file))

    # Remove the temporary file
    temp_file.unlink()

    return result

# âœ… Run the server
if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8080)
